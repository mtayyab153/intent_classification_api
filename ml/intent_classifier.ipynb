{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPdtmOZIGPKHwXc/Rn0EEDx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ko_DOWMxTNo8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Load Datset**"],"metadata":{"id":"d1RRACWyyaNv"}},{"cell_type":"code","source":["# looad datasets\n","import pandas as pd\n","\n","train_df = pd.read_csv('/content/drive/My Drive/new_train.csv')\n","val_df = pd.read_csv('/content/drive/My Drive/new_val.csv')\n","test_df = pd.read_csv('/content/drive/My Drive/new_test.csv')\n","\n","\n","print(\"Train DataFrame head:\")\n","print(train_df.head())\n","print(len(train_df))\n","\n","print(\"\\nVal DataFrame head:\")\n","print(val_df.head())\n","print(len(val_df))\n","\n","print(\"\\nTest DataFrame head:\")\n","print(test_df.head())\n","print(len(test_df))"],"metadata":{"id":"ExatO0xkyXgf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e8b36025"},"source":["**Data Pre-Processing**"]},{"cell_type":"code","source":["# Text cleaning, normalization and chunking\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","nltk.download(\"stopwords\")\n","nltk.download(\"wordnet\")\n","\n","stop_words = set(stopwords.words(\"english\"))\n","lemmatizer = WordNetLemmatizer()\n","\n","def clean_text(text):\n","    text = text.lower().strip()                        # lowercase and strip\n","    text = re.sub(r'http\\S+|www\\S+', '', text)         # remove urls\n","    text = re.sub(r'\\S+@\\S+', '', text)                # remove emails\n","    text = re.sub(r'\\d+', '', text)                    # remove numbers\n","    text = re.sub(r'[^a-z\\s]', '', text)               # remove punctuation/symbols\n","    tokens = text.split()                              # tokenize\n","    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n","    # tokens = [lemmatizer.lemmatize(w) for w in tokens] # keep stopwords\n","    return \" \".join(tokens)\n","\n","train_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text)\n","val_df[\"clean_text\"]   = val_df[\"text\"].apply(clean_text)\n","test_df[\"clean_text\"]  = test_df[\"text\"].apply(clean_text)\n","\n","print(\"Sample Cleaned Training Data:\\n\", train_df[\"clean_text\"].head())\n","print(\"Sample Cleaned Validation Data:\\n\", val_df[\"clean_text\"].head())\n","print(\"Sample Cleaned Testing Data:\\n\", test_df[\"clean_text\"].head())\n","\n","train_df.to_csv(\"train_cleaned.csv\")"],"metadata":{"id":"fpTuXhwuZuFg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check imbalancing\n","from collections import Counter\n","\n","print(\"Training set class distribution:\")\n","print(Counter(train_df[\"label\"]))\n"],"metadata":{"id":"N4uyTuxdjBcY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Feature extracion and Model Selection**"],"metadata":{"id":"N2Nue726y31_"}},{"cell_type":"code","source":["# Vectorization (Pipeline)\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Initialize TF-IDF vectorizer\n","vectorizer = TfidfVectorizer(\n","    max_features=5000,     # keep top 5000 features\n","    ngram_range=(1,2),     # unigrams + bigrams\n","    stop_words=\"english\"   # optional: remove stopwords\n","    # stop_words=None\n",")\n","\n","# Fit on training data, transform train/val/test\n","X_train = vectorizer.fit_transform(train_df[\"clean_text\"])\n","X_val   = vectorizer.transform(val_df[\"clean_text\"])\n","X_test  = vectorizer.transform(test_df[\"clean_text\"])\n","\n","\n","y_train = train_df[\"label\"]\n","y_val   = val_df[\"label\"]\n","y_test  = test_df[\"label\"]\n","\n","print(\"Train shape:\", X_train.shape)\n","print(\"Validation shape:\", X_val.shape)\n","print(\"Test shape:\", X_test.shape)\n"],"metadata":{"id":"Qe_VEKMBSUS_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Development & Optimization**"],"metadata":{"id":"OBSO7gaCz4th"}},{"cell_type":"code","metadata":{"id":"ae57756b"},"source":["# logistic regression\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV, cross_val_score\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Define model\n","log_reg = LogisticRegression(max_iter=500)\n","\n","# Hyperparameter grid\n","param_grid = {\n","    'C': [0.01, 1, 5],        # Regularization strength\n","    'penalty': ['l2'],         # L2 regularization\n","    'solver': ['lbfgs', 'liblinear']\n","}\n","\n","# Grid search with 5-fold cross-validation\n","grid = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n","grid.fit(X_train, y_train)\n","\n","# Best model\n","best_log_reg = grid.best_estimator_\n","print(\"Best Parameters:\", grid.best_params_)\n","\n","# Evaluate on validation set\n","y_val_pred = best_log_reg.predict(X_val)\n","print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n","print(classification_report(y_val, y_val_pred))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Comprehensive Evaluation**"],"metadata":{"id":"ycSEBHYG1LsW"}},{"cell_type":"code","source":["# Core Metrics\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Predictions on test set\n","y_test_pred = best_log_reg.predict(X_test)\n","\n","# Accuracy\n","acc = accuracy_score(y_test, y_test_pred)\n","print(\"Test Accuracy:\", acc)\n","\n","# Precision, Recall, F1-score per class\n","print(classification_report(y_test, y_test_pred))\n"],"metadata":{"id":"ii4yXxZ-hJ1F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save model\n","import joblib\n","\n","# Save trained vectorizer and model\n","joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n","joblib.dump(best_log_reg, \"intent_classifier.pkl\")"],"metadata":{"id":"DJCISH_0-LsJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# confusion matrix\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","# Compute confusion matrix\n","cm = confusion_matrix(y_test, y_test_pred, labels=best_log_reg.classes_)\n","\n","# Plot\n","plt.figure(figsize=(8,6))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","            xticklabels=best_log_reg.classes_,\n","            yticklabels=best_log_reg.classes_)\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"Actual\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()"],"metadata":{"id":"hFEKo_WAsn7f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# classification performance chart\n","from sklearn.metrics import precision_recall_fscore_support\n","import numpy as np\n","\n","# Compute metrics\n","precision, recall, f1, support = precision_recall_fscore_support(y_test, y_test_pred, labels=best_log_reg.classes_)\n","\n","x = np.arange(len(best_log_reg.classes_))\n","width = 0.2\n","\n","plt.figure(figsize=(10,6))\n","plt.bar(x - width, precision, width, label='Precision', color='skyblue')\n","plt.bar(x, recall, width, label='Recall', color='lightgreen')\n","plt.bar(x + width, f1, width, label='F1-score', color='salmon')\n","\n","plt.xticks(x, best_log_reg.classes_)\n","plt.ylim(0, 1.1)\n","plt.ylabel(\"Score\")\n","plt.title(\"Classification Performance per Class\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"wPff4NWFtORO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# learning curves\n","from sklearn.model_selection import learning_curve\n","import numpy as np\n","\n","train_sizes, train_scores, val_scores = learning_curve(\n","    best_log_reg, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1,\n","    train_sizes=np.linspace(0.3, 1.0, 10)\n",")\n","\n","train_mean = np.mean(train_scores, axis=1)\n","val_mean = np.mean(val_scores, axis=1)\n","\n","plt.figure(figsize=(8,6))\n","plt.plot(train_sizes, train_mean, 'o-', label=\"Training Accuracy\")\n","plt.plot(train_sizes, val_mean, 'o-', label=\"Validation Accuracy\")\n","plt.xlabel(\"Training Set Size\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Learning Curve\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"VRyNctOLuAEq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Feature Importance\n","import pandas as pd\n","import numpy as np\n","\n","feature_names = vectorizer.get_feature_names_out()\n","coef = best_log_reg.coef_\n","\n","# For multi-class, each row corresponds to a class\n","for i, class_label in enumerate(best_log_reg.classes_):\n","    top_features = np.argsort(coef[i])[-10:]  # Top 10 features\n","    print(f\"Top features for class '{class_label}':\")\n","    print([feature_names[j] for j in top_features])\n","    print()"],"metadata":{"id":"4pkZw4BswGEo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prediction Confidence & Thresholding\n","import matplotlib.pyplot as plt\n","\n","# Probabilities\n","y_proba = best_log_reg.predict_proba(X_test)\n","\n","# Max confidence per sample\n","max_conf = y_proba.max(axis=1)\n","\n","plt.figure(figsize=(8,5))\n","plt.hist(max_conf, bins=20, color='skyblue', edgecolor='black')\n","plt.xlabel(\"Prediction Confidence\")\n","plt.ylabel(\"Number of Samples\")\n","plt.title(\"Prediction Confidence Distribution\")\n","plt.show()\n","\n","# Optional: Thresholding example (e.g., only accept predictions with >0.8 confidence)\n","threshold = 0.8\n","y_pred_thresh = [best_log_reg.classes_[np.argmax(p)] if max(p) >= threshold else \"uncertain\" for p in y_proba]\n"],"metadata":{"id":"7e6MPH9ZwQtX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Error Analysis & Insights**"],"metadata":{"id":"rwsN6Z8JzYWS"}},{"cell_type":"code","source":["# 1. Analyze Misclassified Examples\n","import pandas as pd\n","\n","# Get predictions and probabilities\n","y_test_pred = best_log_reg.predict(X_test)\n","y_test_proba = best_log_reg.predict_proba(X_test)\n","\n","# Find misclassified samples\n","misclassified_idx = np.where(y_test != y_test_pred)[0]\n","\n","# Create a DataFrame for inspection\n","error_df = pd.DataFrame({\n","    \"True_Label\": y_test[misclassified_idx],\n","    \"Predicted_Label\": y_test_pred[misclassified_idx],\n","    \"Confidence\": np.max(y_test_proba[misclassified_idx], axis=1)\n","})\n","\n","print(\"Misclassified examples:\")\n","print(error_df.head(10))"],"metadata":{"id":"xNbhmKIEzeSq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confidence-based Prediction Filtering\n","threshold = 0.8\n","filtered_preds = []\n","for i, probs in enumerate(y_test_proba):\n","    if np.max(probs) >= threshold:\n","        filtered_preds.append(y_test_pred[i])   # confident prediction\n","    else:\n","        filtered_preds.append(\"uncertain\")      # mark as uncertain\n","print(filtered_preds)"],"metadata":{"id":"mYe4nLcHz2yt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Error Types**\n","\n","- **Systematic Errors**: Model confuses two classes (e.g., web_search vs general_chat).\n","\n","- **Ambiguity Errors**: When Input text is genuinely vague. (e.g., \"remind me later\" could be calendar or chat).\n","\n","- **Data Quality Errors**: Typos, short inputs etc..\n","\n","- **Imbalanced Class Errors**: If one class has more data in this case   **web_search** class is bigger.\n","\n","- **Numeric Inputs**: If we give numeric input, the model predicts wrong intent.\n","\n","**Improvements**\n","\n","- We need to add more diverse training data for confusing classes.\n","\n","- Try with other vectoirzation techniques.\n","\n","- Consider class-weight adjustment in Logistic Regression to balance misclassification.\n","\n","- Try alternative models (SVM, Random Forest,deep learning, ...).\n","\n","- For vague and numeric inputs, we can try input validation and confidence threshold i.e check confidence_score if it's less than x.x , return \"uncertain\" instead of wrong label.\n","\n","- For **general_chat** and **knowledge_query** classes, model is overfitting, for it some of techniques could be used i.e data set review etc.."],"metadata":{"id":"hEug-DKl0j-v"}},{"cell_type":"markdown","source":["**Model Limitations & Edge Cases**\n","\n","Model struggles with short, vague queries.\n","\n","Some queries belong to multiple classes at once (multi-label issue).\n","\n","Limited generalization outside the training dataset\n","\n","returns wrong intent if we give numeric input.\n","\n","if model isn't confident enough to predict, then we can implement confidence based filtering to return \"unknown.\""],"metadata":{"id":"UldIzGlL02zx"}}]}